{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cce6b-9f60-4670-8285-fb02e50b899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from selenium import webdriver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b17b0-484c-481b-a0ba-10a0263641d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years stats are tracked\n",
    "years = list(range(1991, 2024))\n",
    "main_url = \"https://www.basketball-reference.com/awards/awards_{}.html\"\n",
    "\n",
    "# retrieve mvp ladder data tables for each year \n",
    "for year in years:\n",
    "    url = main_url.format(year)\n",
    "    data = requests.get(url)\n",
    "    time.sleep(10)\n",
    "    # save data in mvp_data folder\n",
    "    with open(\"mvp_data/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed58b63-c329-4db0-8188-668208f339bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mvp_data/1991.html\") as f:\n",
    "    page = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "# remove header of table\n",
    "soup.find('tr', class_= \"over_header\").decompose()\n",
    "# find data table using its id\n",
    "mvp_table = soup.find(id = \"mvp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75379960-079f-4830-bc57-576932836e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single table from 1991\n",
    "mvp_1991 = pd.read_html(StringIO(str(mvp_table)))[0]\n",
    "mvp_1991.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0d1ec-3c76-4025-8ffa-69f53ce738a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_tables = []\n",
    "\n",
    "# loop through all year files and store the tables\n",
    "for year in years:\n",
    "    with open(\"mvp_data/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_= \"over_header\").decompose()\n",
    "    mvp_table = soup.find_all(id=\"mvp\")[0]\n",
    "    mvp_df = pd.read_html(StringIO(str(mvp_table)))[0]\n",
    "    mvp_df[\"Year\"] = year\n",
    "    tables.append(mvp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a033f30-233e-4f38-9b4a-4e6446b0fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the tables\n",
    "all_mvps = pd.concat(tables)\n",
    "all_mvps.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14dc2b67-bf8e-4ef0-a472-daf7619a6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Stats URL\n",
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\"\n",
    "# Chrome Driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae74a4e5-e6f4-49ab-b653-2247125b058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each stats page\n",
    "years = list(range(1991, 2024))\n",
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "    driver.get(url)\n",
    "    #scroll to bottom of page to get whole table\n",
    "    driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "\n",
    "    with open(\"player_data/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89356010-6c8e-4e9f-b6e8-5bead7b3282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for player stats files each year and add to table\n",
    "player_stats_df = []\n",
    "\n",
    "years = list(range(1991, 2024))\n",
    "for year in years:\n",
    "    with open(\"player_data/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    # remove table header elements\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    stats_table = soup.find_all(id=\"per_game_stats\")[0]\n",
    "    stats_df = pd.read_html(StringIO(str(stats_table)))[0]\n",
    "    stats_df[\"Year\"] = year\n",
    "    player_stats_df.append(stats_df)\n",
    "\n",
    "# concatenate all years' tables\n",
    "player_stats = pd.concat(player_stats_df)\n",
    "player_stats.to_csv(\"player_stats.csv\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5aeeb4e6-cec5-4a87-9b6b-a87cd25270b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Team W/L Record\n",
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\"\n",
    "\n",
    "# put html pages into folder\n",
    "years = list(range(2022, 2024))\n",
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    team_data = requests.get(url)\n",
    "    time.sleep(5)\n",
    "    with open(\"team_data/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(team_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d7b666e-797a-4204-92de-7f81b865d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse W/L record based on conferences\n",
    "team_df = []\n",
    "years = list(range(1991, 2024))\n",
    "for year in years:\n",
    "    with open(\"team_data/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    # Eastern Conf.\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    soup.find('tr', class_= 'thead').decompose()\n",
    "    east_table = soup.find_all(id=\"divs_standings_E\")[0]\n",
    "    east_df = pd.read_html(StringIO(str(east_table)))[0]\n",
    "    east_df[\"Year\"] = year\n",
    "    east_df[\"Team\"] = east_df[\"Eastern Conference\"]\n",
    "    del east_df[\"Eastern Conference\"]\n",
    "    team_df.append(east_df)\n",
    "\n",
    "    # Western Conf.\n",
    "    west_table = soup.find_all(id=\"divs_standings_W\")[0]\n",
    "    west_df = pd.read_html(StringIO(str(west_table)))[0]\n",
    "    west_df[\"Year\"] = year\n",
    "    west_df[\"Team\"] = west_df[\"Western Conference\"]\n",
    "    del west_df[\"Western Conference\"]\n",
    "    team_df.append(west_df)\n",
    "    \n",
    "teams = pd.concat(team_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9bc52441-159b-42ea-9099-bdd14d03d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv file\n",
    "teams.to_csv(\"teams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
